{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & Dependencies\n",
        "\n",
        "This section installs necessary libraries and sets up the environment.\n",
        "If running locally, install the following:\n"
      ],
      "metadata": {
        "id": "_DUPkcRMXwkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qxhn4hxXZL7"
      },
      "outputs": [],
      "source": [
        "# Install only if not already available\n",
        "# !pip install textattack transformers datasets scikit-learn matplotlib scipy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load & Prepare SST-2 Dataset\n",
        "\n",
        "We use the GLUE SST-2 dataset and split it into clean and perturbable halves.\n"
      ],
      "metadata": {
        "id": "eu554sn7X7Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "train_data = dataset[\"train\"].select(range(5000))  # Subsample for efficiency\n",
        "\n",
        "# Split into two halves for clean and adversarial\n",
        "clean_data = train_data.select(range(2500))\n",
        "perturb_data = train_data.select(range(2500, 5000))\n",
        "\n",
        "# Save split datasets\n",
        "clean_data.to_json(\"sst2_clean_split.json\")\n",
        "perturb_data.to_json(\"sst2_perturb_split.json\")"
      ],
      "metadata": {
        "id": "U9WB1_joX57P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generate Adversarial Samples with TextFooler\n",
        "\n",
        "We use TextAttack's implementation of TextFooler to generate adversarial versions of input text.\n"
      ],
      "metadata": {
        "id": "-aoDLINlYcjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load pre-trained tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "classifier = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Wrap model for TextAttack\n",
        "wrapped_model = HuggingFaceModelWrapper(classifier, tokenizer)\n",
        "\n",
        "# Initialize TextFooler Attack\n",
        "attack = TextFoolerJin2019.build(wrapped_model)\n",
        "\n",
        "# Apply adversarial attack\n",
        "perturbed_texts = []\n",
        "for example in tqdm(perturb_data, desc=\"Applying TextFooler Attack\"):\n",
        "    input_text = example['sentence']\n",
        "    ground_truth_label = example['label']\n",
        "    try:\n",
        "        adv_example = attack.attack(input_text, ground_truth_label)\n",
        "        adv_text = adv_example.perturbed_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating adversarial example: {e}\")\n",
        "        adv_text = input_text\n",
        "    #perturbed_texts.append({\"sentence\": adv_text, \"label\": ground_truth_label})\n",
        "    perturbed_texts.append({\n",
        "    \"original_sentence\": input_text,\n",
        "    \"sentence\": adv_text,\n",
        "    \"label\": ground_truth_label\n",
        "})\n",
        "\n",
        "# Convert to Dataset format\n",
        "perturbed_dataset = Dataset.from_list(perturbed_texts)\n",
        "perturbed_dataset.to_json(\"sst2_textfooler_split.json\")"
      ],
      "metadata": {
        "id": "A3FflJsXYj4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Balanced Dataset\n",
        "\n",
        "Merge clean and adversarial examples into a final balanced dataset.\n"
      ],
      "metadata": {
        "id": "IeEYLFIMY-GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the clean and perturbed datasets to generate balanced dataset\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "clean_data = Dataset.from_json(\"sst2_clean_split.json\")\n",
        "perturbed_data = Dataset.from_json(\"sst2_textfooler_split.json\")\n",
        "\n",
        "num_samples = min(len(clean_data), len(perturbed_data))\n",
        "clean_data = clean_data.select(range(num_samples))\n",
        "perturbed_data = perturbed_data.select(range(num_samples))\n",
        "\n",
        "# Convert to lists and filter out invalid entries\n",
        "#clean_list = [ex for ex in clean_data.to_list() if ex[\"sentence\"] is not None]\n",
        "clean_list = [{\"original_sentence\": ex[\"sentence\"], \"sentence\": ex[\"sentence\"], \"label\": ex[\"label\"]}\n",
        "              for ex in clean_data.to_list() if ex[\"sentence\"] is not None]\n",
        "perturbed_list = [ex for ex in perturbed_data.to_list() if ex[\"sentence\"] is not None]\n",
        "\n",
        "# Merge clean and perturbed datasets\n",
        "final_dataset = Dataset.from_list(clean_list + perturbed_list)\n",
        "final_dataset.to_json(\"sst2_final_balanced_textfooler.json\")\n",
        "\n",
        "print(\"Final balanced dataset (50% clean, 50% TextFooler-attacked) saved as 'sst2_final_balanced_textfooler.json'\")\n"
      ],
      "metadata": {
        "id": "ssI9qEvQZCIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Detection, Model Training & Evaluation\n",
        "\n",
        "In this section, we train a DistilBERT classifier on the SST-2 dataset (with clean and adversarial samples), extract logits and embeddings, and evaluate detection performance.\n",
        "\n",
        "We use:\n",
        "- **Logit difference** to measure prediction shifts\n",
        "- **Embedding similarity** to detect semantic drift\n",
        "- **Threshold tuning** for optimal F1, AUC, and Attack Success Rate (ASR)\n"
      ],
      "metadata": {
        "id": "I_Njcz3tZE_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detection and model evaluation\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Load combined dataset after TextFooler attack\n",
        "final_dataset = Dataset.from_json(\"sst2_final_balanced_textfooler.json\")\n",
        "print(\"Dataset columns:\", final_dataset.column_names)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenizing dataset\n",
        "def tokenize_function(examples):\n",
        "    if \"sentence\" not in examples:\n",
        "        raise ValueError(\"Dataset does not contain a 'sentence' column. Available columns: \" + str(final_dataset.column_names))\n",
        "    return tokenizer([str(s) for s in examples[\"sentence\"]], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "# Filter dataset to remove invalid inputs\n",
        "filtered_dataset = final_dataset.filter(lambda x: isinstance(x[\"sentence\"], str) and x[\"sentence\"].strip() != \"\")\n",
        "\n",
        "# Apply tokenization\n",
        "try:\n",
        "    tokenized_dataset = filtered_dataset.map(tokenize_function, batched=True)\n",
        "except ValueError as e:\n",
        "    print(\"Error during tokenization:\", e)\n",
        "    print(\"Example dataset structure:\", filtered_dataset[0])  # Debugging info\n",
        "    exit()\n",
        "\n",
        "# Define model\n",
        "classifier = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"sst2_trained_model\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=classifier,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "SAVE_PATH = \"sst2_trained_model\"\n",
        "classifier.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "print(f\"Trained model saved to '{SAVE_PATH}'\")\n",
        "\n",
        "# Function to extract logits\n",
        "def get_logits(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(classifier.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = classifier(**inputs)\n",
        "    return outputs.logits.squeeze().cpu().numpy()\n",
        "\n",
        "# Function to extract embeddings from hidden layers\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(classifier.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = classifier(**inputs, output_hidden_states=True)\n",
        "    return outputs.hidden_states[-1].mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "# Function to compute logit and embedding differences\n",
        "def compute_detection_features(original_text, adversarial_text):\n",
        "    orig_logits = get_logits(original_text)\n",
        "    adv_logits = get_logits(adversarial_text)\n",
        "\n",
        "    logit_diff = float(np.linalg.norm(orig_logits - adv_logits))  # Logit difference\n",
        "\n",
        "    orig_embedding = get_embedding(original_text)\n",
        "    adv_embedding = get_embedding(adversarial_text)\n",
        "    embed_similarity = float(1 - cosine(orig_embedding, adv_embedding))  # Embedding similarity\n",
        "\n",
        "    return logit_diff, embed_similarity\n",
        "\n",
        "# Evaluate detection on final dataset\n",
        "detection_results = []\n",
        "for example in tqdm(filtered_dataset, desc=\"Evaluating Detection\"):\n",
        "    text = example['sentence']\n",
        "    label = example['label']\n",
        "    #logit_diff, embed_similarity = compute_detection_features(text, text)\n",
        "    logit_diff, embed_similarity = compute_detection_features(example['original_sentence'], example['sentence'])\n",
        "    detected = int(logit_diff > 0.08 or embed_similarity < 0.75)  # Explicit detection flag\n",
        "    detection_results.append({\n",
        "        \"text\": text,\n",
        "        \"logit_diff\": logit_diff,\n",
        "        \"embed_similarity\": embed_similarity,\n",
        "        \"label\": label,\n",
        "        \"detected\": detected\n",
        "    })\n",
        "\n",
        "# Save detection results\n",
        "with open(\"sst2_adversarial_detection_results.json\", \"w\") as f:\n",
        "    json.dump(detection_results, f, indent=4)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "LOGIT_DIFF_VALUES = np.arange(0.1, 0.5, 0.08)\n",
        "EMBED_SIM_VALUES = np.arange(0.7, 0.9, 0.08)\n",
        "best_f1, best_auc = 0, 0\n",
        "best_thresholds = (None, None)\n",
        "all_tuning_results = []\n",
        "\n",
        "for logit_thresh, embed_thresh in product(LOGIT_DIFF_VALUES, EMBED_SIM_VALUES):\n",
        "    for res in detection_results:\n",
        "        res[\"detected\"] = res[\"logit_diff\"] > logit_thresh or res[\"embed_similarity\"] < embed_thresh\n",
        "\n",
        "    true_labels = [res[\"label\"] for res in detection_results]\n",
        "    predicted_labels = [1 if res[\"detected\"] else 0 for res in detection_results]\n",
        "\n",
        "    if len(set(true_labels)) > 1:\n",
        "        auc = roc_auc_score(true_labels, predicted_labels)\n",
        "    else:\n",
        "        auc = 0\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n",
        "    all_tuning_results.append({\n",
        "        \"logit_threshold\": logit_thresh,\n",
        "        \"embed_threshold\": embed_thresh,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1_score\": f1,\n",
        "        \"auc\": auc\n",
        "    })\n",
        "\n",
        "    if f1 > best_f1 or (f1 == best_f1 and auc > best_auc):\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_thresholds = (logit_thresh, embed_thresh)\n",
        "\n",
        "# Compute ASR\n",
        "misclassified_adversarial = sum(1 for res in detection_results if res[\"label\"] == 1 and res[\"detected\"] == 0)\n",
        "total_adversarial = sum(1 for res in detection_results if res[\"label\"] == 1)\n",
        "asr = misclassified_adversarial / total_adversarial if total_adversarial > 0 else 0\n",
        "print(f\"Attack Success Rate (ASR): {asr:.2%}\")\n",
        "\n",
        "# Save tuning results\n",
        "with open(\"sst2_threshold_tuning_results.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"best_thresholds\": best_thresholds,\n",
        "        \"best_f1_score\": best_f1,\n",
        "        \"best_auc\": best_auc,\n",
        "        \"attack_success_rate\": asr,\n",
        "        \"all_results\": all_tuning_results\n",
        "    }, f, indent=4)\n",
        "\n",
        "print(\"Best thresholds, Accuracy, F1 Score, AUC, and Attack Success Rate saved.\")"
      ],
      "metadata": {
        "id": "ZuNqQip-ZGRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}